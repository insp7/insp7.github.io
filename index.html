<!DOCTYPE HTML>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Aniket Konkar</title>
        <meta name="author" content="Aniket Konkar">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
        <link rel="stylesheet" type="text/css" href="stylesheet.css">
    </head>
    <body>
        <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr style="padding:0px">
                    <td style="padding:0px">
                        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                                <tr style="padding:0px">
                                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                                        <p class="name" style="text-align: center;">
                                            Aniket Konkar
                                        </p>
                                        <p>
                                            I am interested in computer vision, robotics, and neuromorphic computing. 
                                            Currently, I'm working on creating a dataset of event camera recordings of objects responding to sound stimuli and exploring methods to reconstruct the original acoustic signals from these events. I am fortunate to be supervised by Prof. <a href="https://cs.engineering.gwu.edu/robert-pless">Robert Pless</a>.
                                        </p>
                                        <p>
                                          I graduated with an MS in Computer Science from George Washington University. I enjoyed working as a research assistant under the supervision of Prof. <a href="https://gwipp.gwu.edu/rob-olsen-research-professor">Rob Olsen</a>, gaining experience in data analysis and modeling. I also have two years of professional experience as a Software Engineer.
                                        </p>
                                        <p style="text-align:center">
                                            <a href="mailto:aniket.konkar@gwu.edu"><i class="fa-solid"></i>Email</a> &nbsp;/&nbsp;
                                            <a href="data/Konkar_Aniket_CV.pdf"><i class="fa-solid"></i>CV</a> &nbsp;/&nbsp;
                                            <a href="https://scholar.google.com/citations?user=KEKRlR0AAAAJ&hl=en"><i class="fa-brands"></i>Scholar</a> &nbsp;/&nbsp;
                                            <a href="https://www.github.com/insp7/"><i class="fa-brands"></i>GitHub</a> &nbsp;/&nbsp;
                                            <a href="https://www.linkedin.com/in/aniket-konkar16/"><i class="fa-brands"></i>LinkedIn</a>
                                            
                                        </p>
                                    </td>
                                    <td style="padding:2.5%;width:37%;max-width:37%">
                                        <a href="images/ak.PNG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%; border: 3px solid #dcdcdc;" alt="profile photo" src="images/ak.PNG" class="hoverZoomLink"></a>
                                    </td>
                                </tr>
                            </tbody>
                        </table>

                        <h2 style="padding:0 16px; width:100%; vertical-align:middle;">Publications</h2>
                        <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                                <!-- Paper 1 -->
                                <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <img src="images/Simple_Transformer_model_architecture.PNG" width="100%">
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                        <a href="https://openaccess.thecvf.com/content/WACV2025W/EVGEN/html/Kumar_Simple_Transformer_with_Single_Leaky_Neuron_for_Event_Vision_WACVW_2025_paper.html">
                                        <span class="papertitle">Simple Transformer with Single Leaky Neuron for Event Vision</span>
                                        </a>
                                        <br>
                                        <a href="https://himanshu9084.github.io/">Himanshu Kumar</a>,
                                        <strong>Aniket Konkar</strong>
                                        <br>
                                        <em>WACV Workshop</em>, 2025
                                        <br>
                                        <a href="data/WACV_Workshop_2025_42x84_poster.pdf">Poster</a>
                                        /
                                        <a href="https://openaccess.thecvf.com/content/WACV2025W/EVGEN/papers/Kumar_Simple_Transformer_with_Single_Leaky_Neuron_for_Event_Vision_WACVW_2025_paper.pdf">PDF</a>
                                        /
                                        <a href="https://github.com/himanshu9084/Simple_transformer_leaky_neuron">Code</a>
                                        <p>
                                            This paper presents a lightweight Transformer combining a ResNet feature extractor, a spiking PLIF neuron, and multi-head attention for event-based vision, achieving 98.3% on DVS Gesture, 99.3% on N-MNIST, and 75.9% on CIFAR10-DVS.
                                            Our model outperforms several event-driven and spiking architectures — including transformer-based ones — while matching the accuracy of far more complex models at a fraction of their computational cost. Despite comparable performance, it uses 4× fewer parameters than transformer-based spiking models (15.3M vs. 60–66M) and achieves inference with over an order of magnitude fewer synaptic operations (1.82G vs. 9.74–65.28G SOPs).
                                        </p>
                                    </td>
                                </tr>

                                <!-- Paper 2 -->
                                 <tr>
                                    <td style="padding:16px;width:20%;vertical-align:middle">
                                        <img src="images/eeg_and_transformer_papers_2019_2024.PNG" width="100%">
                                    </td>
                                    <td style="padding:8px;width:80%;vertical-align:middle">
                                      <a href="https://faculty.cs.gwu.edu/xiaodongqu/papers/HCII_2025_1286_Transformer_EEG_review.pdf">
                                        <span class="papertitle">A Review of Transformer-Based and Hybrid Deep Learning Approaches for EEG Analysis</span>
                                      </a>
                                      <br>
                                      <strong>Aniket Konkar</strong>,
                                      <a href="https://faculty.cs.gwu.edu/xiaodongqu/">Xiaodong Qu</a>
                                      <br>
                                      <em>HCI International</em>, 2025
                                      <br>
                                      <p>
                                          A review paper highlighting how transformer-based and hybrid deep learning models advance EEG decoding across tasks while identifying key trends, gaps, and future research directions.
                                      </p>
                                    </td>
                                </tr>
                            </tbody>
                        </table>

                        <h2 style="padding:0 16px; width:100%; vertical-align:middle;">Notes & Experiments</h2>
                        <table style="width:100%;border:0;border-spacing:0 8px;border-collapse:separate;">
                            <tr>
                                <td style="padding:8px 16px;">
                                <a href="posts/seeing-motion-from-sound.html">
                                    <span class="papertitle">Seeing Motion from Sound with Event Cameras</span>
                                </a>
                                <br>
                                <span style="font-size:14px;color:#666;">
                                    Exploratory observation using a Prophesee EVK4 event camera
                                </span>
                                </td>
                            </tr>
                        </table>

                        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                                <tr>
                                    <td style="padding:0px">
                                        <br>
                                        <p style="text-align:right;font-size:small;">
                                            Thank you to <a href="https://jonbarron.info/">Jon Barron</a> for this awesome template.
                                        </p>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </td>
                </tr>
        </table>
    </body>
</html>